import tensorflow as tf
import tensorflow_addons as tfa
import numpy as np
import pandas as pd

from gislr_transformer.config import *
from gislr_transformer.helpers import *
from gislr_transformer.models import Embedding, Transformer
from gislr_transformer.callbacks import *

def triplet_loss(inputs, dist='sqeuclidean', margin='maxplus'):
    alpha, mult = 1, 1e10
    anchor, positive, negative = inputs
    positive_distance = tf.square(anchor - positive)
    negative_distance = tf.square(anchor - negative)
    if dist == 'euclidean':
        positive_distance = tf.sqrt(tf.reduce_sum(positive_distance, axis=-1, keepdims=True))
        negative_distance = tf.sqrt(tf.reduce_sum(negative_distance, axis=-1, keepdims=True))
    elif dist == 'sqeuclidean':
        positive_distance = tf.reduce_sum(positive_distance, axis=-1, keepdims=True)
        negative_distance = tf.reduce_sum(negative_distance, axis=-1, keepdims=True)
    loss = positive_distance - negative_distance
    if margin == 'maxplus':
        loss = tf.maximum(0.0, alpha + loss*mult)
    elif margin == 'softplus':
        loss = tf.math.log(alpha + tf.math.exp(loss))
    loss = tf.reduce_mean(loss, axis=-2) # mean across all 64 frames
    loss = tf.math.l2_normalize(loss, axis=0) # L2 normalization

    return tf.reduce_mean(loss)

def triplet_loss_np(inputs, dist='sqeuclidean', margin='maxplus'):
    alpha, mult = 1, 1e5
    anchor, positive, negative = inputs
    positive_distance = np.square(anchor - positive)
    negative_distance = np.square(anchor - negative)
    if dist == 'euclidean':
        positive_distance = np.sqrt(np.sum(positive_distance, axis=-1, keepdims=True))
        negative_distance = np.sqrt(np.sum(negative_distance, axis=-1, keepdims=True))
    elif dist == 'sqeuclidean':
        positive_distance = np.sum(positive_distance, axis=-1, keepdims=True)
        negative_distance = np.sum(negative_distance, axis=-1, keepdims=True)
    loss = positive_distance - negative_distance
    if margin == 'maxplus':
        loss = np.maximum(0.0, alpha + loss*mult)
    elif margin == 'softplus':
        loss = np.log(alpha + np.exp(loss))
    return np.mean(loss)

# Custom sampler to get a batch containing N times all signs
def triplet_get_train_batch_all_signs(X, y, NON_EMPTY_FRAME_IDXS, n, num_classes, hard_classes, meta_df, train_all):
    # Arrays to store batch in
    X_batch = np.zeros([num_classes*n, CFG.INPUT_SIZE*3, CFG.N_COLS, CFG.N_DIMS], dtype=np.float32)
    y_batch = np.arange(0, num_classes, step=1/(n), dtype=np.float32).astype(np.int64)
    non_empty_frame_idxs_batch = np.zeros([num_classes*n, CFG.INPUT_SIZE*3], dtype=np.float32)

    # Dictionary mapping ordinally encoded sign to corresponding sample indices
    CLASS2IDXS = {}
    for i in range(num_classes):
        CLASS2IDXS[i] = np.argwhere(y == i).squeeze().astype(np.int32)
        
    # Difficult class mapping (which classes are commonly mistaken)
    if train_all == False:
        DIFFICULT_CLASS_MAP = {0: [58, 112, 127, 172, 176, 184, 188, 204, 237, 244], 1: [21, 38, 79, 84, 85, 107, 113, 154, 188, 212], 2: [9, 24, 42, 57, 60, 65, 67, 69, 171, 204], 3: [28, 30, 45, 71, 122, 131, 175, 188, 214, 221], 4: [14, 21, 33, 44, 48, 55, 58, 69, 183, 203], 5: [7, 9, 10, 15, 108, 125, 152, 218, 231, 248], 6: [7, 20, 22, 36, 71, 94, 116, 158, 180, 246], 7: [6, 35, 54, 71, 94, 116, 131, 133, 221, 246], 8: [1, 15, 16, 35, 37, 64, 65, 92, 168, 220], 9: [22, 45, 53, 65, 77, 84, 115, 153, 211, 236], 10: [3, 7, 12, 17, 35, 128, 144, 156, 221, 245], 11: [30, 60, 61, 131, 135, 146, 165, 230, 233, 245], 12: [10, 16, 45, 51, 68, 160, 190, 211, 243, 245], 13: [17, 18, 21, 22, 33, 85, 105, 151, 160, 214], 14: [18, 25, 44, 48, 75, 159, 162, 189, 194, 208], 15: [5, 94, 95, 108, 116, 125, 126, 152, 218, 249], 16: [12, 15, 22, 24, 30, 36, 68, 73, 109, 169], 17: [18, 19, 21, 26, 45, 135, 174, 181, 227, 241], 18: [13, 17, 26, 45, 63, 85, 113, 181, 188, 241], 19: [13, 17, 31, 33, 38, 46, 78, 79, 101, 129], 20: [18, 21, 46, 84, 85, 95, 147, 163, 188, 201], 21: [1, 17, 18, 22, 84, 116, 161, 163, 170, 246], 22: [6, 7, 9, 13, 16, 21, 71, 93, 151, 214], 23: [24, 37, 47, 59, 67, 98, 167, 180, 224, 236], 24: [6, 16, 30, 45, 64, 73, 110, 169, 217, 220], 25: [14, 23, 64, 69, 89, 98, 128, 138, 175, 200], 26: [17, 28, 38, 46, 113, 147, 154, 170, 227, 241], 27: [21, 26, 28, 46, 62, 84, 157, 161, 188, 216], 28: [13, 17, 27, 33, 79, 124, 161, 188, 216, 241], 29: [30, 48, 51, 60, 82, 112, 113, 118, 152, 165], 30: [16, 50, 60, 71, 119, 146, 207, 217, 230, 246], 31: [1, 17, 19, 33, 69, 113, 160, 181, 212, 241], 32: [19, 23, 30, 33, 49, 53, 58, 75, 114, 148], 33: [35, 42, 44, 48, 60, 69, 113, 160, 183, 203], 34: [16, 101, 108, 123, 147, 154, 157, 243, 246, 249], 35: [1, 10, 37, 60, 61, 64, 109, 152, 196, 244], 36: [6, 44, 62, 76, 139, 141, 142, 153, 186, 249], 37: [7, 10, 12, 35, 47, 64, 158, 180, 224, 244], 38: [19, 26, 52, 89, 99, 102, 129, 170, 202, 240], 39: [32, 44, 63, 65, 84, 86, 90, 101, 172, 214], 40: [56, 74, 124, 127, 136, 184, 187, 196, 204, 228], 41: [43, 44, 52, 68, 72, 92, 118, 151, 201, 223], 42: [2, 4, 33, 44, 45, 125, 128, 160, 171, 175], 43: [41, 96, 112, 134, 136, 185, 191, 214, 218, 236], 44: [3, 14, 21, 25, 33, 42, 45, 48, 124, 174], 45: [3, 4, 28, 42, 44, 57, 160, 171, 175, 211], 46: [20, 26, 27, 84, 85, 124, 160, 161, 188, 214], 47: [16, 46, 59, 69, 109, 122, 167, 174, 177, 220], 48: [4, 14, 33, 55, 82, 100, 112, 133, 183, 187], 49: [19, 32, 63, 64, 86, 87, 93, 138, 161, 165], 50: [2, 9, 21, 28, 30, 48, 60, 175, 243, 245], 51: [15, 29, 48, 50, 60, 110, 113, 177, 245, 249], 52: [15, 22, 38, 41, 63, 65, 72, 73, 223, 249], 53: [0, 56, 74, 112, 117, 153, 170, 179, 192, 193], 54: [6, 9, 15, 27, 36, 43, 151, 157, 185, 192], 55: [45, 60, 64, 82, 84, 100, 106, 133, 140, 210], 56: [21, 61, 74, 117, 184, 192, 204, 209, 231, 249], 57: [3, 9, 45, 70, 89, 98, 143, 160, 171, 211], 58: [30, 74, 76, 83, 102, 131, 135, 164, 179, 192], 59: [8, 14, 25, 32, 47, 91, 122, 148, 162, 204], 60: [29, 30, 33, 50, 51, 67, 108, 114, 119, 152], 61: [35, 64, 77, 133, 152, 180, 196, 220, 239, 244], 62: [27, 36, 57, 101, 116, 141, 142, 180, 216, 232], 63: [14, 19, 32, 33, 39, 48, 69, 159, 201, 215], 64: [12, 25, 35, 61, 127, 152, 165, 204, 207, 244], 65: [8, 9, 24, 39, 66, 76, 109, 149, 159, 249], 66: [8, 14, 48, 65, 74, 91, 107, 168, 201, 236], 67: [23, 25, 45, 69, 90, 98, 99, 120, 180, 222], 68: [16, 41, 76, 109, 111, 125, 135, 217, 226, 245], 69: [4, 42, 49, 82, 93, 98, 100, 124, 152, 181], 70: [45, 57, 85, 89, 112, 133, 211, 213, 225, 240], 71: [1, 6, 7, 12, 101, 172, 176, 201, 221, 246], 72: [41, 52, 73, 78, 134, 149, 169, 201, 217, 222], 73: [16, 24, 30, 64, 83, 93, 96, 149, 169, 189], 74: [53, 56, 90, 97, 127, 166, 184, 187, 193, 211], 75: [1, 4, 14, 38, 81, 99, 145, 161, 178, 242], 76: [16, 68, 92, 139, 142, 164, 176, 186, 226, 246], 77: [0, 33, 56, 61, 78, 89, 187, 220, 224, 236], 78: [19, 30, 82, 89, 107, 183, 208, 215, 225, 247], 79: [1, 44, 45, 107, 124, 181, 208, 212, 234, 238], 80: [33, 48, 77, 85, 203, 206, 213, 225, 232, 247], 81: [13, 33, 75, 112, 120, 154, 203, 210, 227, 232], 82: [9, 55, 79, 100, 112, 113, 140, 177, 198, 227], 83: [0, 24, 58, 73, 88, 97, 111, 164, 169, 237], 84: [1, 9, 18, 21, 27, 85, 105, 107, 108, 188], 85: [1, 13, 20, 46, 84, 100, 106, 170, 172, 216], 86: [1, 32, 49, 61, 87, 95, 113, 123, 124, 128], 87: [15, 38, 45, 49, 65, 95, 118, 128, 138, 229], 88: [24, 41, 73, 83, 146, 169, 217, 230, 237, 249], 89: [4, 19, 56, 69, 77, 78, 79, 81, 196, 208], 90: [2, 21, 35, 45, 56, 65, 74, 122, 159, 171], 91: [59, 83, 115, 117, 141, 156, 159, 220, 227, 236], 92: [8, 45, 59, 76, 91, 95, 109, 131, 159, 231], 93: [9, 22, 83, 101, 105, 106, 120, 121, 138, 163], 94: [6, 7, 8, 12, 116, 158, 180, 186, 221, 245], 95: [87, 91, 92, 128, 139, 141, 152, 207, 231, 235], 96: [20, 85, 102, 134, 146, 149, 168, 191, 222, 223], 97: [47, 83, 88, 102, 109, 146, 163, 230, 235, 237], 98: [3, 9, 23, 25, 58, 67, 69, 153, 171, 222], 99: [1, 33, 44, 69, 75, 100, 145, 177, 181, 241], 100: [7, 21, 32, 48, 55, 99, 140, 145, 183, 210], 101: [17, 22, 39, 63, 73, 85, 144, 151, 189, 213], 102: [58, 61, 97, 125, 164, 167, 204, 224, 226, 236], 103: [12, 16, 30, 41, 49, 59, 112, 118, 201, 248], 104: [38, 55, 60, 91, 100, 106, 133, 135, 217, 240], 105: [9, 13, 84, 85, 93, 121, 143, 173, 214, 238], 106: [5, 15, 91, 107, 110, 127, 198, 231, 236, 240], 107: [1, 19, 38, 63, 78, 79, 145, 202, 206, 225], 108: [5, 15, 28, 42, 95, 105, 126, 152, 231, 248], 109: [5, 15, 35, 47, 92, 108, 169, 176, 196, 230], 110: [13, 20, 22, 103, 106, 117, 118, 128, 201, 217], 111: [41, 52, 68, 72, 76, 125, 131, 135, 217, 228], 112: [0, 4, 40, 42, 48, 56, 74, 90, 183, 204], 113: [14, 18, 29, 31, 75, 81, 82, 177, 203, 241], 114: [23, 32, 40, 67, 74, 98, 108, 112, 117, 192], 115: [9, 56, 58, 114, 131, 215, 216, 220, 224, 237], 116: [6, 7, 30, 71, 94, 156, 158, 180, 231, 246], 117: [24, 33, 41, 53, 56, 64, 163, 169, 192, 193], 118: [12, 32, 86, 87, 110, 124, 128, 163, 165, 201], 119: [9, 11, 60, 61, 88, 91, 95, 152, 204, 248], 120: [13, 49, 81, 101, 106, 138, 213, 219, 235, 242], 121: [9, 13, 78, 93, 120, 171, 173, 211, 238, 247], 122: [3, 64, 90, 139, 156, 158, 159, 162, 167, 174], 123: [12, 35, 63, 77, 78, 81, 126, 157, 215, 249], 124: [33, 45, 46, 47, 64, 69, 133, 152, 160, 203], 125: [5, 10, 15, 20, 35, 64, 68, 126, 243, 249], 126: [6, 26, 40, 95, 108, 152, 166, 215, 231, 244], 127: [0, 40, 56, 74, 90, 136, 172, 184, 187, 204], 128: [25, 33, 42, 78, 87, 110, 118, 129, 152, 193], 129: [19, 20, 38, 95, 105, 128, 179, 190, 193, 202], 130: [14, 48, 64, 66, 194, 197, 202, 210, 213, 229], 131: [9, 11, 58, 61, 77, 109, 115, 146, 221, 230], 132: [15, 64, 70, 140, 173, 190, 205, 206, 238, 248], 133: [16, 17, 20, 73, 91, 93, 106, 163, 197, 219], 134: [15, 41, 43, 96, 149, 185, 191, 218, 222, 223], 135: [11, 29, 63, 68, 111, 113, 133, 146, 182, 230], 136: [0, 30, 44, 63, 73, 117, 127, 184, 187, 193], 137: [2, 11, 33, 44, 48, 68, 81, 109, 135, 154], 138: [15, 20, 49, 93, 101, 120, 163, 178, 219, 242], 139: [5, 37, 76, 116, 142, 156, 186, 231, 246, 249], 140: [21, 30, 55, 60, 79, 82, 100, 132, 152, 211], 141: [36, 62, 95, 142, 144, 163, 197, 206, 232, 235], 142: [6, 16, 36, 62, 76, 94, 95, 116, 139, 186], 143: [9, 13, 21, 28, 42, 105, 132, 173, 236, 249], 144: [4, 33, 40, 44, 45, 80, 141, 183, 190, 216], 145: [17, 38, 48, 75, 99, 101, 181, 199, 211, 234], 146: [2, 6, 11, 30, 53, 88, 135, 220, 233, 239], 147: [20, 26, 42, 93, 144, 154, 161, 198, 216, 227], 148: [23, 32, 59, 90, 103, 155, 162, 194, 230, 236], 149: [43, 65, 72, 73, 96, 134, 155, 185, 222, 223], 150: [17, 18, 112, 163, 176, 178, 199, 200, 220, 242], 151: [13, 22, 54, 61, 86, 87, 95, 101, 201, 214], 152: [33, 64, 69, 85, 124, 147, 151, 171, 175, 207], 153: [77, 112, 175, 183, 184, 187, 196, 204, 228, 237], 154: [20, 26, 38, 42, 51, 59, 70, 81, 177, 183], 155: [1, 30, 72, 134, 149, 154, 169, 180, 223, 224], 156: [10, 21, 122, 148, 158, 159, 162, 171, 221, 246], 157: [15, 21, 22, 34, 71, 123, 125, 166, 240, 243], 158: [6, 10, 37, 59, 116, 122, 148, 152, 156, 221], 159: [14, 44, 116, 120, 122, 139, 148, 156, 162, 239], 160: [33, 42, 45, 82, 112, 124, 136, 150, 175, 211], 161: [3, 21, 27, 28, 45, 46, 69, 124, 163, 212], 162: [1, 14, 25, 32, 44, 59, 116, 122, 148, 159], 163: [20, 97, 161, 195, 197, 200, 207, 210, 219, 235], 164: [7, 30, 32, 41, 52, 83, 102, 156, 201, 221], 165: [16, 24, 29, 37, 48, 60, 63, 135, 187, 249], 166: [2, 16, 62, 74, 123, 126, 132, 199, 243, 248], 167: [23, 40, 47, 54, 59, 74, 91, 109, 168, 176], 168: [59, 61, 91, 92, 102, 112, 156, 167, 176, 237], 169: [16, 24, 30, 52, 73, 74, 83, 88, 150, 217], 170: [17, 18, 21, 26, 27, 30, 131, 140, 161, 228], 171: [18, 25, 57, 67, 98, 122, 128, 160, 162, 211], 172: [39, 40, 95, 127, 134, 138, 151, 187, 193, 204], 173: [8, 19, 21, 105, 121, 143, 195, 211, 248, 249], 174: [3, 44, 53, 59, 76, 90, 121, 122, 211, 236], 175: [3, 42, 45, 47, 53, 57, 74, 124, 171, 234], 176: [0, 10, 47, 61, 109, 125, 167, 204, 226, 244], 177: [19, 59, 69, 82, 100, 113, 114, 136, 148, 227], 178: [64, 95, 130, 138, 141, 163, 199, 200, 210, 249], 179: [18, 20, 42, 58, 84, 105, 115, 129, 184, 193], 180: [16, 47, 61, 74, 94, 127, 167, 196, 204, 231], 181: [1, 13, 45, 57, 69, 75, 79, 194, 211, 212], 182: [48, 49, 103, 111, 135, 138, 154, 163, 197, 224], 183: [1, 4, 33, 48, 112, 124, 130, 182, 187, 203], 184: [0, 40, 56, 74, 112, 127, 136, 153, 187, 220], 185: [43, 54, 96, 134, 139, 149, 191, 218, 223, 249], 186: [12, 33, 36, 37, 76, 139, 142, 202, 226, 228], 187: [40, 56, 61, 64, 127, 136, 164, 167, 204, 220], 188: [1, 18, 21, 27, 46, 53, 84, 85, 105, 186], 189: [17, 80, 81, 120, 151, 163, 178, 213, 232, 235], 190: [12, 47, 123, 125, 152, 157, 180, 205, 215, 243], 191: [43, 65, 134, 149, 164, 185, 222, 231, 236, 247], 192: [9, 15, 53, 54, 56, 74, 112, 117, 193, 231], 193: [21, 32, 41, 45, 103, 117, 129, 136, 179, 249], 194: [9, 41, 65, 90, 91, 130, 148, 156, 162, 181], 195: [42, 108, 132, 154, 211, 236, 238, 240, 241, 248], 196: [9, 12, 15, 35, 64, 124, 126, 180, 190, 244], 197: [9, 16, 48, 93, 106, 130, 163, 187, 207, 210], 198: [1, 13, 104, 106, 110, 133, 206, 211, 227, 240], 199: [17, 49, 87, 95, 100, 150, 178, 200, 210, 242], 200: [49, 85, 110, 128, 150, 163, 178, 199, 201, 242], 201: [22, 41, 44, 110, 118, 124, 128, 208, 223, 224], 202: [8, 16, 87, 120, 128, 130, 138, 162, 206, 229], 203: [4, 29, 48, 78, 89, 183, 225, 227, 238, 247], 204: [4, 40, 82, 111, 112, 127, 136, 140, 187, 210], 205: [2, 6, 21, 33, 35, 45, 180, 190, 215, 245], 206: [38, 78, 95, 107, 132, 141, 202, 225, 240, 247], 207: [6, 60, 64, 118, 124, 130, 133, 152, 163, 165], 208: [3, 14, 20, 44, 75, 89, 95, 201, 225, 247], 209: [0, 4, 8, 53, 54, 56, 95, 121, 218, 249], 210: [29, 33, 60, 64, 106, 113, 133, 135, 163, 197], 211: [1, 42, 45, 57, 124, 130, 160, 171, 173, 206], 212: [1, 27, 31, 33, 69, 75, 79, 181, 234, 241], 213: [13, 70, 80, 101, 175, 198, 202, 206, 214, 242], 214: [1, 13, 22, 46, 87, 95, 105, 151, 188, 213], 215: [2, 6, 10, 12, 21, 78, 190, 205, 225, 245], 216: [21, 27, 84, 100, 105, 115, 147, 196, 207, 230], 217: [16, 24, 30, 68, 72, 73, 88, 110, 169, 198], 218: [15, 21, 27, 43, 76, 185, 191, 209, 236, 249], 219: [8, 20, 22, 38, 48, 120, 125, 138, 141, 163], 220: [7, 9, 47, 61, 64, 65, 91, 115, 224, 249], 221: [10, 30, 35, 71, 131, 156, 230, 233, 245, 246], 222: [25, 43, 67, 69, 96, 98, 134, 185, 191, 223], 223: [41, 96, 134, 149, 155, 168, 191, 201, 222, 224], 224: [7, 39, 61, 94, 122, 167, 168, 220, 223, 239], 225: [2, 33, 45, 70, 78, 89, 107, 203, 206, 247], 226: [0, 16, 30, 61, 88, 102, 125, 207, 236, 243], 227: [17, 21, 26, 81, 91, 100, 106, 147, 177, 198], 228: [9, 17, 20, 40, 112, 125, 127, 153, 172, 181], 229: [20, 54, 103, 114, 120, 121, 172, 178, 180, 234], 230: [11, 30, 64, 82, 88, 102, 131, 204, 228, 237], 231: [15, 44, 56, 62, 64, 116, 139, 142, 180, 249], 232: [80, 81, 144, 147, 154, 189, 206, 213, 216, 240], 233: [10, 11, 63, 109, 131, 135, 146, 216, 230, 239], 234: [56, 75, 79, 90, 112, 115, 145, 184, 212, 235], 235: [95, 97, 141, 145, 163, 178, 189, 232, 234, 242], 236: [9, 15, 61, 90, 116, 125, 174, 195, 231, 249], 237: [0, 21, 58, 64, 76, 109, 125, 131, 153, 230], 238: [95, 121, 126, 132, 139, 163, 178, 195, 235, 248], 239: [3, 23, 59, 102, 131, 148, 156, 224, 233, 236], 240: [80, 85, 104, 110, 147, 157, 197, 198, 206, 227], 241: [17, 18, 19, 21, 26, 31, 99, 113, 135, 177], 242: [38, 49, 87, 97, 128, 150, 166, 199, 200, 207], 243: [2, 9, 34, 50, 123, 125, 126, 157, 230, 245], 244: [10, 35, 37, 61, 64, 102, 122, 126, 152, 196], 245: [10, 50, 60, 64, 78, 94, 116, 180, 205, 215], 246: [6, 7, 15, 71, 94, 116, 156, 180, 221, 231], 247: [57, 70, 75, 78, 99, 107, 145, 203, 206, 225], 248: [5, 56, 119, 125, 132, 140, 152, 195, 236, 238], 249: [4, 5, 6, 15, 21, 23, 61, 65, 125, 236]}
    else:
        DIFFICULT_CLASS_MAP = {0: [58, 112, 113, 127, 133, 136, 167, 176, 184, 237], 1: [21, 38, 79, 84, 85, 113, 133, 154, 188, 212], 2: [9, 24, 42, 57, 70, 153, 171, 204, 225, 239], 3: [28, 30, 71, 122, 131, 133, 175, 188, 208, 214], 4: [33, 44, 48, 55, 58, 69, 112, 121, 183, 203], 5: [15, 21, 108, 121, 125, 152, 180, 218, 231, 248], 6: [7, 21, 22, 36, 62, 71, 116, 158, 180, 246], 7: [6, 35, 54, 71, 94, 113, 116, 133, 221, 246], 8: [10, 35, 37, 64, 65, 92, 133, 158, 168, 220], 9: [22, 29, 45, 53, 65, 84, 115, 153, 211, 236], 10: [3, 7, 12, 35, 94, 128, 144, 156, 221, 245], 11: [30, 60, 61, 131, 135, 146, 165, 230, 233, 245], 12: [10, 45, 51, 68, 160, 186, 190, 211, 243, 245], 13: [17, 22, 33, 85, 105, 120, 151, 160, 181, 214], 14: [18, 25, 27, 44, 48, 75, 159, 162, 194, 208], 15: [5, 94, 95, 108, 116, 125, 157, 180, 218, 249], 16: [12, 15, 24, 52, 68, 73, 109, 133, 146, 169], 17: [18, 19, 21, 26, 45, 135, 174, 181, 227, 241], 18: [13, 17, 26, 45, 85, 113, 179, 181, 188, 241], 19: [13, 17, 31, 33, 38, 46, 78, 79, 101, 129], 20: [18, 46, 84, 85, 125, 129, 147, 163, 188, 201], 21: [15, 17, 20, 27, 84, 116, 161, 163, 170, 246], 22: [6, 7, 9, 13, 20, 71, 85, 93, 151, 214], 23: [3, 24, 37, 59, 98, 167, 180, 224, 236, 239], 24: [6, 16, 30, 45, 64, 73, 110, 169, 217, 220], 25: [14, 23, 64, 67, 69, 89, 98, 128, 138, 200], 26: [17, 21, 28, 38, 46, 113, 133, 147, 227, 241], 27: [1, 21, 26, 28, 46, 53, 84, 161, 188, 216], 28: [13, 27, 33, 79, 124, 161, 188, 216, 232, 241], 29: [48, 51, 60, 82, 112, 113, 118, 133, 152, 165], 30: [3, 16, 29, 50, 51, 52, 60, 94, 207, 230], 31: [1, 17, 19, 26, 33, 69, 113, 181, 212, 241], 32: [14, 19, 23, 30, 33, 49, 58, 75, 114, 148], 33: [28, 35, 42, 44, 48, 60, 69, 113, 160, 183], 34: [16, 20, 101, 108, 123, 133, 157, 243, 246, 249], 35: [1, 10, 60, 61, 64, 109, 152, 176, 196, 244], 36: [6, 44, 62, 76, 139, 142, 153, 186, 196, 249], 37: [10, 35, 44, 115, 139, 158, 180, 202, 224, 244], 38: [19, 26, 89, 102, 104, 129, 170, 202, 206, 240], 39: [32, 44, 63, 65, 84, 86, 90, 101, 172, 214], 40: [56, 74, 112, 127, 136, 184, 187, 196, 204, 228], 41: [8, 38, 43, 52, 68, 72, 94, 201, 223, 226], 42: [2, 4, 33, 44, 45, 128, 160, 171, 175, 207], 43: [41, 58, 96, 112, 134, 185, 191, 218, 222, 236], 44: [14, 25, 33, 40, 45, 48, 124, 125, 174, 183], 45: [3, 42, 44, 57, 74, 133, 160, 171, 175, 211], 46: [20, 26, 27, 84, 85, 124, 160, 161, 188, 214], 47: [16, 46, 59, 69, 109, 122, 167, 177, 220, 237], 48: [4, 14, 33, 55, 82, 100, 112, 133, 183, 187], 49: [17, 19, 32, 63, 64, 86, 87, 93, 104, 138], 50: [2, 9, 30, 51, 60, 64, 133, 175, 243, 245], 51: [29, 48, 50, 60, 110, 113, 133, 165, 177, 207], 52: [15, 16, 22, 38, 41, 47, 63, 72, 223, 249], 53: [0, 56, 74, 112, 117, 153, 170, 179, 192, 193], 54: [6, 9, 15, 20, 27, 36, 151, 157, 185, 192], 55: [4, 25, 45, 48, 82, 100, 106, 133, 140, 210], 56: [53, 61, 74, 117, 184, 192, 204, 209, 231, 249], 57: [9, 45, 70, 89, 98, 121, 133, 160, 171, 211], 58: [30, 74, 76, 83, 102, 115, 131, 135, 164, 179], 59: [14, 23, 25, 32, 47, 91, 122, 148, 162, 204], 60: [29, 30, 33, 50, 51, 67, 108, 119, 133, 152], 61: [35, 64, 77, 104, 106, 109, 133, 180, 220, 244], 62: [27, 36, 57, 101, 116, 141, 142, 216, 231, 232], 63: [14, 19, 32, 48, 69, 159, 201, 205, 215, 239], 64: [12, 25, 35, 61, 127, 152, 196, 204, 207, 244], 65: [8, 9, 24, 39, 66, 76, 109, 133, 220, 249], 66: [8, 14, 47, 48, 65, 74, 91, 92, 107, 220], 67: [23, 25, 28, 45, 69, 90, 98, 171, 180, 222], 68: [16, 41, 76, 104, 109, 111, 125, 135, 169, 217], 69: [4, 42, 45, 82, 98, 100, 113, 124, 152, 181], 70: [45, 85, 107, 112, 132, 133, 211, 213, 225, 240], 71: [6, 7, 12, 22, 94, 101, 172, 176, 221, 246], 72: [41, 52, 73, 78, 134, 149, 169, 201, 217, 222], 73: [16, 24, 30, 64, 83, 88, 96, 149, 169, 189], 74: [46, 53, 56, 90, 127, 184, 187, 192, 193, 211], 75: [1, 4, 14, 38, 99, 145, 160, 161, 178, 242], 76: [16, 36, 68, 92, 115, 139, 142, 164, 186, 226], 77: [0, 56, 61, 78, 89, 113, 220, 224, 236, 249], 78: [19, 82, 89, 107, 113, 133, 177, 208, 225, 247], 79: [1, 44, 45, 140, 181, 188, 208, 212, 234, 238], 80: [33, 48, 62, 81, 85, 206, 213, 225, 232, 247], 81: [13, 33, 70, 112, 120, 154, 203, 210, 227, 232], 82: [55, 79, 100, 113, 133, 140, 177, 198, 211, 227], 83: [0, 24, 52, 58, 73, 88, 97, 164, 169, 237], 84: [1, 9, 18, 21, 27, 85, 105, 107, 108, 188], 85: [1, 13, 20, 46, 84, 100, 106, 170, 188, 216], 86: [1, 32, 49, 61, 87, 95, 104, 113, 123, 128], 87: [15, 29, 38, 49, 86, 95, 118, 128, 138, 229], 88: [24, 29, 73, 83, 146, 169, 217, 230, 237, 249], 89: [4, 12, 48, 56, 77, 78, 133, 195, 196, 208], 90: [0, 2, 21, 35, 65, 74, 122, 133, 159, 171], 91: [59, 83, 115, 117, 156, 159, 220, 227, 236, 240], 92: [8, 29, 76, 91, 95, 109, 131, 159, 220, 231], 93: [9, 22, 58, 83, 101, 102, 105, 106, 121, 138], 94: [6, 7, 8, 12, 116, 158, 180, 186, 221, 245], 95: [87, 91, 92, 128, 139, 141, 179, 231, 235, 249], 96: [20, 85, 102, 134, 146, 149, 179, 191, 222, 223], 97: [47, 58, 88, 102, 109, 146, 163, 230, 235, 237], 98: [9, 23, 25, 42, 58, 64, 67, 69, 153, 222], 99: [1, 33, 44, 69, 75, 100, 145, 177, 181, 241], 100: [7, 55, 91, 99, 113, 133, 140, 145, 183, 210], 101: [17, 22, 27, 39, 63, 73, 85, 151, 189, 213], 102: [58, 61, 83, 97, 117, 125, 133, 164, 226, 236], 103: [12, 16, 30, 35, 41, 49, 53, 59, 201, 248], 104: [38, 55, 60, 91, 100, 106, 133, 135, 217, 240], 105: [13, 20, 84, 121, 133, 143, 173, 214, 238, 248], 106: [29, 91, 104, 107, 110, 127, 133, 198, 231, 240], 107: [19, 38, 53, 63, 78, 145, 206, 225, 247, 248], 108: [5, 15, 42, 95, 105, 121, 126, 152, 231, 248], 109: [5, 15, 35, 47, 92, 108, 169, 176, 196, 220], 110: [13, 20, 22, 103, 106, 117, 118, 128, 133, 201], 111: [14, 41, 68, 72, 133, 135, 137, 182, 217, 228], 112: [4, 40, 48, 56, 74, 111, 119, 133, 183, 204], 113: [18, 26, 29, 31, 75, 81, 82, 177, 203, 241], 114: [23, 32, 40, 53, 98, 112, 117, 136, 192, 234], 115: [9, 56, 114, 131, 133, 215, 216, 220, 224, 237], 116: [6, 7, 30, 71, 94, 156, 158, 180, 231, 246], 117: [24, 53, 56, 64, 133, 136, 163, 169, 192, 193], 118: [12, 32, 86, 87, 110, 124, 128, 163, 165, 201], 119: [9, 11, 29, 60, 61, 88, 91, 152, 204, 248], 120: [13, 49, 70, 81, 121, 138, 213, 219, 235, 242], 121: [9, 13, 93, 120, 132, 171, 173, 211, 238, 247], 122: [3, 64, 90, 139, 156, 158, 159, 162, 167, 174], 123: [12, 77, 78, 107, 126, 133, 157, 215, 247, 249], 124: [45, 46, 64, 69, 107, 126, 133, 152, 160, 203], 125: [5, 10, 12, 15, 35, 64, 126, 186, 243, 249], 126: [6, 26, 40, 95, 108, 152, 166, 215, 231, 244], 127: [0, 40, 56, 74, 90, 136, 172, 184, 187, 204], 128: [25, 33, 42, 78, 87, 110, 118, 129, 152, 193], 129: [19, 38, 74, 105, 128, 136, 179, 190, 193, 202], 130: [14, 48, 64, 194, 197, 202, 207, 210, 213, 229], 131: [3, 9, 91, 109, 115, 133, 146, 221, 230, 237], 132: [15, 64, 70, 121, 143, 190, 205, 206, 238, 248], 133: [16, 17, 20, 73, 93, 106, 163, 182, 197, 219], 134: [15, 41, 43, 96, 149, 185, 191, 222, 223, 224], 135: [14, 29, 63, 68, 111, 133, 137, 146, 182, 233], 136: [44, 63, 73, 74, 83, 117, 127, 184, 187, 193], 137: [2, 11, 33, 48, 68, 109, 131, 135, 154, 176], 138: [15, 20, 49, 93, 101, 120, 163, 189, 219, 242], 139: [36, 37, 76, 116, 133, 142, 156, 186, 231, 249], 140: [30, 55, 60, 69, 79, 82, 100, 132, 133, 208], 141: [36, 62, 76, 95, 142, 144, 163, 197, 232, 235], 142: [16, 36, 62, 71, 76, 94, 95, 139, 186, 231], 143: [9, 13, 21, 84, 105, 125, 132, 173, 236, 249], 144: [4, 33, 40, 44, 45, 80, 141, 147, 183, 232], 145: [17, 75, 99, 101, 146, 181, 199, 211, 212, 234], 146: [2, 11, 30, 53, 88, 135, 137, 220, 233, 239], 147: [6, 20, 26, 62, 93, 144, 161, 198, 216, 227], 148: [23, 32, 59, 90, 103, 115, 155, 194, 236, 239], 149: [43, 65, 72, 73, 96, 134, 155, 185, 222, 223], 150: [17, 18, 153, 163, 176, 178, 199, 200, 220, 242], 151: [13, 22, 54, 61, 86, 87, 95, 101, 201, 214], 152: [6, 33, 35, 64, 69, 85, 124, 151, 175, 215], 153: [58, 77, 112, 136, 175, 183, 184, 187, 196, 228], 154: [20, 26, 42, 59, 68, 70, 81, 163, 177, 183], 155: [30, 72, 134, 149, 154, 168, 169, 180, 223, 224], 156: [10, 116, 122, 133, 148, 158, 171, 180, 221, 246], 157: [15, 34, 71, 113, 123, 125, 133, 166, 231, 243], 158: [6, 37, 59, 94, 116, 122, 133, 152, 156, 221], 159: [14, 44, 120, 122, 139, 148, 156, 162, 181, 208], 160: [33, 42, 45, 82, 112, 124, 136, 150, 175, 211], 161: [3, 21, 26, 27, 28, 45, 46, 124, 147, 163], 162: [14, 25, 32, 44, 59, 116, 122, 133, 148, 159], 163: [97, 161, 195, 197, 200, 207, 210, 216, 219, 235], 164: [7, 30, 32, 41, 52, 83, 102, 156, 201, 221], 165: [16, 24, 29, 37, 60, 63, 133, 135, 187, 249], 166: [2, 16, 62, 74, 123, 126, 132, 199, 242, 243], 167: [40, 47, 59, 74, 77, 102, 109, 133, 168, 176], 168: [59, 61, 102, 139, 164, 167, 175, 176, 220, 237], 169: [24, 30, 52, 73, 74, 83, 88, 133, 150, 217], 170: [17, 18, 21, 27, 30, 113, 131, 140, 188, 228], 171: [25, 57, 67, 98, 122, 128, 133, 160, 162, 211], 172: [39, 40, 95, 112, 127, 134, 138, 151, 187, 204], 173: [21, 105, 121, 133, 143, 195, 211, 238, 248, 249], 174: [3, 44, 53, 76, 79, 90, 121, 122, 211, 236], 175: [3, 42, 45, 47, 53, 74, 124, 171, 192, 234], 176: [0, 47, 61, 109, 113, 125, 167, 188, 204, 226], 177: [59, 69, 75, 82, 100, 113, 114, 133, 148, 227], 178: [64, 138, 141, 163, 199, 200, 210, 235, 242, 249], 179: [18, 20, 42, 58, 74, 115, 129, 184, 188, 193], 180: [16, 47, 61, 74, 94, 184, 187, 196, 204, 231], 181: [1, 13, 14, 26, 45, 69, 75, 79, 194, 212], 182: [48, 49, 103, 111, 117, 138, 154, 163, 197, 224], 183: [4, 14, 33, 48, 81, 112, 154, 182, 203, 204], 184: [0, 40, 56, 74, 112, 127, 136, 153, 187, 220], 185: [43, 54, 96, 133, 134, 149, 191, 218, 223, 249], 186: [12, 33, 36, 37, 76, 139, 142, 202, 226, 228], 187: [40, 56, 61, 74, 127, 133, 136, 164, 204, 220], 188: [1, 18, 20, 21, 46, 53, 84, 85, 105, 186], 189: [1, 17, 31, 69, 120, 151, 178, 213, 232, 235], 190: [12, 47, 115, 123, 125, 152, 196, 205, 215, 243], 191: [43, 102, 134, 149, 164, 185, 222, 231, 236, 247], 192: [53, 54, 56, 74, 112, 113, 117, 133, 193, 231], 193: [21, 53, 74, 103, 117, 129, 136, 179, 192, 249], 194: [9, 41, 65, 90, 130, 133, 148, 156, 162, 181], 195: [42, 108, 132, 154, 211, 236, 238, 240, 241, 248], 196: [35, 64, 113, 124, 126, 133, 180, 184, 190, 244], 197: [9, 29, 48, 93, 106, 130, 163, 187, 207, 210], 198: [1, 104, 106, 110, 133, 206, 211, 217, 227, 240], 199: [17, 49, 87, 95, 100, 150, 178, 200, 210, 242], 200: [49, 85, 110, 150, 163, 178, 199, 201, 235, 242], 201: [22, 41, 44, 72, 102, 110, 128, 208, 223, 224], 202: [8, 16, 37, 87, 120, 130, 156, 162, 206, 229], 203: [4, 29, 48, 81, 89, 133, 154, 183, 225, 247], 204: [4, 40, 82, 90, 111, 112, 127, 187, 210, 228], 205: [6, 35, 107, 113, 124, 152, 180, 190, 215, 245], 206: [38, 78, 95, 107, 132, 141, 179, 195, 240, 247], 207: [64, 68, 104, 106, 118, 130, 133, 152, 163, 165], 208: [3, 14, 20, 75, 89, 95, 201, 207, 225, 247], 209: [0, 53, 56, 95, 121, 192, 217, 218, 231, 249], 210: [29, 33, 60, 64, 106, 113, 133, 135, 163, 197], 211: [12, 42, 45, 57, 124, 143, 160, 171, 173, 195], 212: [1, 31, 33, 69, 75, 79, 181, 234, 237, 241], 213: [13, 27, 70, 80, 101, 132, 202, 206, 214, 232], 214: [1, 13, 20, 22, 29, 46, 105, 151, 188, 213], 215: [2, 6, 78, 125, 126, 133, 152, 190, 205, 245], 216: [21, 27, 84, 85, 100, 115, 131, 147, 196, 230], 217: [16, 24, 30, 68, 73, 88, 110, 111, 169, 198], 218: [5, 15, 21, 43, 76, 185, 191, 209, 236, 249], 219: [8, 18, 22, 97, 120, 125, 133, 138, 141, 163], 220: [7, 9, 47, 61, 65, 91, 139, 224, 231, 249], 221: [10, 35, 71, 94, 131, 156, 158, 230, 245, 246], 222: [25, 43, 67, 69, 96, 98, 134, 185, 191, 223], 223: [41, 96, 134, 149, 155, 168, 185, 191, 222, 224], 224: [39, 61, 66, 94, 122, 167, 168, 220, 223, 239], 225: [2, 70, 78, 89, 107, 160, 180, 203, 206, 247], 226: [0, 16, 36, 61, 88, 102, 125, 164, 207, 243], 227: [17, 81, 91, 106, 147, 154, 177, 183, 198, 232], 228: [9, 17, 20, 29, 40, 112, 125, 127, 153, 186], 229: [20, 54, 75, 97, 114, 172, 178, 180, 202, 234], 230: [11, 30, 64, 74, 82, 83, 88, 204, 228, 237], 231: [9, 44, 62, 64, 116, 139, 142, 180, 184, 249], 232: [71, 80, 81, 144, 147, 154, 213, 216, 235, 240], 233: [10, 11, 63, 131, 133, 135, 146, 216, 230, 239], 234: [29, 56, 75, 79, 90, 133, 145, 184, 212, 235], 235: [27, 95, 97, 141, 145, 163, 178, 189, 216, 242], 236: [5, 9, 56, 61, 125, 174, 195, 220, 231, 249], 237: [0, 21, 47, 58, 109, 125, 131, 153, 170, 230], 238: [95, 121, 126, 130, 132, 138, 163, 178, 235, 248], 239: [3, 23, 59, 102, 131, 148, 156, 224, 233, 236], 240: [80, 104, 110, 133, 147, 157, 197, 198, 206, 227], 241: [17, 18, 19, 21, 26, 31, 99, 113, 177, 188], 242: [38, 49, 97, 128, 150, 178, 199, 200, 207, 235], 243: [20, 34, 50, 71, 123, 125, 126, 157, 190, 245], 244: [10, 35, 37, 61, 64, 102, 106, 122, 126, 196], 245: [10, 12, 50, 60, 64, 78, 94, 180, 205, 215], 246: [6, 7, 15, 30, 71, 94, 116, 180, 221, 231], 247: [57, 70, 78, 79, 89, 107, 145, 203, 206, 225], 248: [5, 56, 119, 125, 132, 140, 152, 195, 211, 238], 249: [15, 21, 35, 56, 61, 77, 125, 180, 195, 236]}
    if hard_classes > 10: 
        raise ValueError('hard_classes must be <= 10.')

    while True:
        # Fill batch arrays
        for i in range(num_classes):
            anchor_idxs = np.random.choice(CLASS2IDXS[i], n, replace=True)
            positive_idxs = np.zeros(n, dtype=np.int64)
            negative_idxs = np.zeros(n, dtype=np.int64)

            for z in range(n):
                participant_id_pos = meta_df[(meta_df.participant_id == meta_df.iloc[anchor_idxs[z]].participant_id) & (meta_df.label==z) & (meta_df.index != anchor_idxs[z])].index
                participant_id_neg = meta_df[(meta_df.participant_id == meta_df.iloc[anchor_idxs[z]].participant_id) & (meta_df.label.isin(DIFFICULT_CLASS_MAP[i][:hard_classes]))].index
                if len(participant_id_pos) == 0 or len(participant_id_neg) == 0:
                    positive_idxs[z] = np.random.choice(CLASS2IDXS[i][0], 1)
                    neg_idxs[z] = np.random.choice(CLASS2IDXS[DIFFICULT_CLASS_MAP[i][0]], 1)
                else:
                    positive_idxs[z] = np.random.choice(participant_id_pos)
                    negative_idxs[z] = np.random.choice(participant_id_neg)

            anchor_idxs = np.random.choice(CLASS2IDXS[i], n)
            positive_idxs = np.random.choice(CLASS2IDXS[i], n)
            neg_idxs = np.random.choice(CLASS2IDXS[i], n)

            X_batch[i*n:(i+1)*n, :CFG.INPUT_SIZE] = X[anchor_idxs]
            X_batch[i*n:(i+1)*n, CFG.INPUT_SIZE:CFG.INPUT_SIZE*2] = X[positive_idxs]
            X_batch[i*n:(i+1)*n, CFG.INPUT_SIZE*2:CFG.INPUT_SIZE*3] = X[neg_idxs]

            non_empty_frame_idxs_batch[i*n:(i+1)*n, :CFG.INPUT_SIZE] = NON_EMPTY_FRAME_IDXS[anchor_idxs]
            non_empty_frame_idxs_batch[i*n:(i+1)*n, CFG.INPUT_SIZE:CFG.INPUT_SIZE*2] = NON_EMPTY_FRAME_IDXS[positive_idxs]
            non_empty_frame_idxs_batch[i*n:(i+1)*n, CFG.INPUT_SIZE*2:CFG.INPUT_SIZE*3] = NON_EMPTY_FRAME_IDXS[neg_idxs]
            yield {'frames': X_batch, 'non_empty_frame_idxs': non_empty_frame_idxs_batch }, y_batch

def triplet_load_data(val_fold, train_all):
    
    meta_df = pd.read_csv(CFG.MY_DATA_DIR + "train.csv")
    X_train = np.load(CFG.MW_DATA_DIR + 'X.npy')
    y_train = np.load(CFG.MW_DATA_DIR + 'y.npy')
    NON_EMPTY_FRAME_IDXS_TRAIN = np.load(CFG.MW_DATA_DIR + '/NON_EMPTY_FRAME_IDXS.npy')

    if train_all == True:
        validation_data = None
    else:
        train_idx = meta_df[meta_df.fold != val_fold].index
        val_idx = meta_df[meta_df.fold == val_fold].index

        # Load Val
        X_val = X_train[val_idx]
        y_val = y_train[val_idx]
        NON_EMPTY_FRAME_IDXS_VAL = NON_EMPTY_FRAME_IDXS_TRAIN[val_idx]

        # Define validation Data
        validation_data = ({'frames': X_val, 'non_empty_frame_idxs': NON_EMPTY_FRAME_IDXS_VAL }, y_val)

        # Load Val
        X_train = X_train[train_idx]
        y_train = y_train[train_idx]
        NON_EMPTY_FRAME_IDXS_TRAIN = NON_EMPTY_FRAME_IDXS_TRAIN[train_idx]

    # Train 
    print_shape_dtype([X_train, y_train, NON_EMPTY_FRAME_IDXS_TRAIN], ['X_train', 'y_train', 'NON_EMPTY_FRAME_IDXS_TRAIN'])
    # Val
    if train_all == False:
        print_shape_dtype([X_val, y_val, NON_EMPTY_FRAME_IDXS_VAL], ['X_val', 'y_val', 'NON_EMPTY_FRAME_IDXS_VAL'])
    # Sanity Check
    print(f'# NaN Values X_train: {np.isnan(X_train).sum()}')
    return X_train, y_train, NON_EMPTY_FRAME_IDXS_TRAIN, validation_data, meta_df

def get_triplet_model(
        units, 
        learning_rate,
        clip_norm,
        statsdict,
        ):
    # Inputs
    frames = tf.keras.layers.Input([CFG.INPUT_SIZE*3, CFG.N_COLS, CFG.N_DIMS], dtype=tf.float32, name='frames')
    non_empty_frame_idxs = tf.keras.layers.Input([CFG.INPUT_SIZE*3], dtype=tf.float32, name='non_empty_frame_idxs')
    
    elayer = Embedding(units)
    
    # 3 Embeddings [anchor, pos, neg]
    # tf.slice(input, begin, size)
    x0 = tf.slice(frames, [0,CFG.INPUT_SIZE*0,0,0], [-1, CFG.INPUT_SIZE, 78, 2])
    x1 = tf.slice(frames, [0,CFG.INPUT_SIZE*1,0,0], [-1, CFG.INPUT_SIZE, 78, 2])
    x2 = tf.slice(frames, [0,CFG.INPUT_SIZE*2,0,0], [-1, CFG.INPUT_SIZE, 78, 2])
    non_empty_frame_idxs0 = tf.slice(non_empty_frame_idxs, [0,CFG.INPUT_SIZE*0], [-1, CFG.INPUT_SIZE])
    non_empty_frame_idxs1 = tf.slice(non_empty_frame_idxs, [0,CFG.INPUT_SIZE*1], [-1, CFG.INPUT_SIZE])
    non_empty_frame_idxs2 = tf.slice(non_empty_frame_idxs, [0,CFG.INPUT_SIZE*2], [-1, CFG.INPUT_SIZE])

    # Padding Mask
    mask0 = tf.expand_dims(tf.cast(tf.math.not_equal(non_empty_frame_idxs0, -1), tf.float32), axis=2)
    mask1 = tf.expand_dims(tf.cast(tf.math.not_equal(non_empty_frame_idxs1, -1), tf.float32), axis=2)
    mask2 = tf.expand_dims(tf.cast(tf.math.not_equal(non_empty_frame_idxs2, -1), tf.float32), axis=2)

    # LIPS
    lips0 = tf.slice(x0, [0,0,CFG.LIPS_START,0], [-1,CFG.INPUT_SIZE, 40, 2])
    lips0 = tf.where(tf.math.equal(lips0, 0.0), 0.0, (lips0 - statsdict["LIPS_MEAN"]) / statsdict["LIPS_STD"])
    lips1 = tf.slice(x1, [0,0,CFG.LIPS_START,0], [-1,CFG.INPUT_SIZE, 40, 2])
    lips1 = tf.where(tf.math.equal(lips1, 0.0), 0.0, (lips1 - statsdict["LIPS_MEAN"]) / statsdict["LIPS_STD"])
    lips2 = tf.slice(x2, [0,0,CFG.LIPS_START,0], [-1,CFG.INPUT_SIZE, 40, 2])
    lips2 = tf.where(tf.math.equal(lips2, 0.0), 0.0, (lips2 - statsdict["LIPS_MEAN"]) / statsdict["LIPS_STD"])    

    # LEFT HAND
    left_hand0 = tf.slice(x0, [0,0,CFG.LEFT_HAND_START,0], [-1,CFG.INPUT_SIZE, 21, 2])
    left_hand0 = tf.where(tf.math.equal(left_hand0, 0.0), 0.0, (left_hand0 - statsdict["LEFT_HANDS_MEAN"]) / statsdict["LEFT_HANDS_STD"])
    left_hand1 = tf.slice(x1, [0,0,CFG.LEFT_HAND_START,0], [-1,CFG.INPUT_SIZE, 21, 2])
    left_hand1 = tf.where(tf.math.equal(left_hand1, 0.0), 0.0, (left_hand1 - statsdict["LEFT_HANDS_MEAN"]) / statsdict["LEFT_HANDS_STD"])
    left_hand2 = tf.slice(x2, [0,0,CFG.LEFT_HAND_START,0], [-1,CFG.INPUT_SIZE, 21, 2])
    left_hand2 = tf.where(tf.math.equal(left_hand2, 0.0), 0.0, (left_hand2 - statsdict["LEFT_HANDS_MEAN"]) / statsdict["LEFT_HANDS_STD"])

    # POSE
    pose0 = tf.slice(x0, [0,0,CFG.POSE_START,0], [-1,CFG.INPUT_SIZE, 17, 2])
    pose0 = tf.where(tf.math.equal(pose0, 0.0),0.0,(pose0 - statsdict["POSE_MEAN"]) / statsdict["POSE_STD"])
    pose1 = tf.slice(x1, [0,0,CFG.POSE_START,0], [-1,CFG.INPUT_SIZE, 17, 2])
    pose1 = tf.where(tf.math.equal(pose1, 0.0),0.0,(pose1 - statsdict["POSE_MEAN"]) / statsdict["POSE_STD"])
    pose2 = tf.slice(x2, [0,0,CFG.POSE_START,0], [-1,CFG.INPUT_SIZE, 17, 2])
    pose2 = tf.where(tf.math.equal(pose2, 0.0),0.0,(pose2 - statsdict["POSE_MEAN"]) / statsdict["POSE_STD"])

    # Flatten
    lips0 = tf.reshape(lips0, [-1, CFG.INPUT_SIZE, 40*2])
    lips1 = tf.reshape(lips1, [-1, CFG.INPUT_SIZE, 40*2])
    lips2 = tf.reshape(lips2, [-1, CFG.INPUT_SIZE, 40*2])
    left_hand0 = tf.reshape(left_hand0, [-1, CFG.INPUT_SIZE, 21*2])
    left_hand1 = tf.reshape(left_hand1, [-1, CFG.INPUT_SIZE, 21*2])
    left_hand2 = tf.reshape(left_hand2, [-1, CFG.INPUT_SIZE, 21*2])
    pose0 = tf.reshape(pose0, [-1, CFG.INPUT_SIZE, 17*2])
    pose1 = tf.reshape(pose1, [-1, CFG.INPUT_SIZE, 17*2])
    pose2 = tf.reshape(pose2, [-1, CFG.INPUT_SIZE, 17*2])
    
    # Embedding
    x0 = elayer(lips0, left_hand0, pose0, non_empty_frame_idxs0)
    # Ignoring gradients for neg and pos sample
    with tf.GradientTape(watch_accessed_variables=False) as tape:
        x1 = elayer(lips1, left_hand1, pose1, non_empty_frame_idxs1)
        x2 = elayer(lips2, left_hand2, pose2, non_empty_frame_idxs2)

    print(x0.shape)
    outputs = [x0, x1, x2]

    # Create Tensorflow Model
    model = tf.keras.models.Model(inputs=[frames, non_empty_frame_idxs], outputs=outputs)
    model.add_loss(triplet_loss(outputs))
    
    # Adam Optimizer with weight decay
    # weight_decay value is overidden by callback
    optimizer = tfa.optimizers.AdamW(learning_rate=learning_rate, clipnorm=clip_norm, weight_decay=1e-5)
    
    model.compile(loss=None, optimizer=optimizer)
    return model

def get_triplet_weights(config, statsdict):

    # Get data
    X_train, y_train, NON_EMPTY_FRAME_IDXS_TRAIN, validation_data, meta_df = triplet_load_data(
        val_fold=config.val_fold,
        train_all=config.train_all,
    )

    # Clear all models in GPU
    tf.keras.backend.clear_session()

    model = get_triplet_model(
        units=config.units, 
        learning_rate=config.triplet_learning_rate,
        clip_norm=config.clip_norm,
        statsdict=statsdict,
    )

    # # NOTE: FOR TESTING (DOESNT TRAIN TRIPLET WEIGHTS)
    # return model.get_layer(name='embedding').weights

    # Get callbacks
    callbacks = get_callbacks(
        model=model,
        epochs=config.triplet_epochs,
        warmup_epochs=config.warmup_epochs,
        lr_max=config.triplet_learning_rate,
        wd_ratio=config.weight_decay,
        do_early_stopping=False,
        no_wandb=True,
        min_delta=config.min_delta,
        patience=config.patience,
    )

    # Actual Training
    history=model.fit(
            x=triplet_get_train_batch_all_signs(
                X_train, 
                y_train, 
                NON_EMPTY_FRAME_IDXS_TRAIN, 
                n=config.batch_all_signs_n,
                num_classes=config.num_classes,
                hard_classes=config.triplet_hard_class_n,
                meta_df=meta_df,
                train_all=config.train_all,
                ),
            steps_per_epoch=len(X_train) // (config.num_classes * config.batch_all_signs_n),
            epochs=config.triplet_epochs,
            # Only used for validation data since training data is a generator
            batch_size=config.batch_size,
            callbacks=callbacks,
            verbose=config.verbose,
        )
    
    emb_layer = model.get_layer(name='embedding')
    return emb_layer

